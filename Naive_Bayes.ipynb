{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZLnBTZmBmAN"
      },
      "source": [
        "#(Model 2)Naive Bayes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Naive Bayes model leverages the assumption of class conditioned independence in order to utilise the theory of Bayes Theorem in predicting the class of a sample, given its underlying distribution and prior probabilities. The posterier probability of a sample belonging to a given class k is given by:\n",
        "\n",
        "$$P(C_k | x) = \\frac{P(x | C_k) \\cdot P(C_k)}{P(x)}$$\n",
        "\n",
        "Bayes theorem is applicable for the implementation of this model because it assumes that the distribution of the input variables are independent of each other conditionally. Under this assumption, the solution using the maximum likelihood function indicates that the training data can be fitted using the labelled data for all individual classes. Keeping in mind the continuous nature of variables present in the dataset, I have implemented the Gaussian Naive Bayes model for solving the problem at hand.\n",
        "\n",
        "$$ f(x | \\mu, \\sigma) = \\frac{1}{\\sqrt{2\\pi}\\sigma} \\cdot e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}}$$\n",
        "\n",
        "Our attribute feature space is 20 dimensionsal, making Naive Bayes model a wise choice for the classification task because of its high efficiency pertaining to high dimensional inputs. The percentage error associated with the classification can be treated as indicator of a certain degree of correlation among the features."
      ],
      "metadata": {
        "id": "EWI-ODH_1e-8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ck4zS5OaWSjk"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from scipy.stats import norm\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Defining a class for our Naive Bayes model\n",
        "class NaiveBayesClassifier:\n",
        "    def __init__(self):\n",
        "        self.class_probs = defaultdict(float)\n",
        "        self.class_means = defaultdict(list)\n",
        "        self.class_stds = defaultdict(list)\n",
        "\n",
        "\n",
        "# This function is utilised to train the data by calculating the associated means and deviations.\n",
        "    def fit(self, X, y):\n",
        "        unique_classes = np.unique(y)\n",
        "\n",
        "        for c in unique_classes:\n",
        "            class_instances = X[y == c]\n",
        "            self.class_probs[c] = len(class_instances) / len(X)\n",
        "            self.class_means[c] = np.mean(class_instances, axis=0)\n",
        "            self.class_stds[c] = np.std(class_instances, axis=0)\n",
        "\n",
        "\n",
        "# The maximum likelihood function associated with the Gaussian probability density is calculated using this function.\n",
        "\n",
        "    def calculate_likelihood(self, x, mean, std):\n",
        "        exponent = np.exp(-((x - mean) ** 2) / (2 * (std ** 2)))\n",
        "        return (1 / (np.sqrt(2 * np.pi) * std)) * exponent\n",
        "\n",
        "\n",
        "# The prediction is made for a single instance of the samples.\n",
        "\n",
        "    def predict_instance(self, x):\n",
        "        likelihoods = {}\n",
        "\n",
        "        for c in self.class_probs:\n",
        "            class_prob = np.log(self.class_probs[c])\n",
        "            class_likelihood = np.sum(np.log(self.calculate_likelihood(x, self.class_means[c], self.class_stds[c])))\n",
        "            likelihoods[c] = class_prob + class_likelihood\n",
        "\n",
        "        return max(likelihoods, key=likelihoods.get)\n",
        "\n",
        "# The consolidated prediction for the complete dataset is made by calling predict_instance for all samples and appending to the predictions array.\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = []\n",
        "\n",
        "        for instance in X:\n",
        "            predictions.append(self.predict_instance(instance))\n",
        "\n",
        "        return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvSYUtoSktkZ",
        "outputId": "1422294f-5090-42e7-ae57-9cc6d2559087"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.71\n"
          ]
        }
      ],
      "source": [
        "# This code block instantiates nb_classifier with the Naive Bayes Classifier class and performs subsequent model fitting and predictions.\n",
        "nb_classifier = NaiveBayesClassifier()\n",
        "\n",
        "# The nb_classifier model employs the 'fit' function to the train the data.\n",
        "nb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Model predictions are now made to get the outcomes using the 'predict' function defined within the classifier class.\n",
        "predictions = nb_classifier.predict(X_test)\n",
        "\n",
        "# The model's utility in solving the classification task is evaluated through the 'accuracy_score' metric from the sklearn library.\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAFBB1aLki-t"
      },
      "source": [
        "## (Model 4) K-Nearest Neighbours"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The k-Nearest Neighbors (KNN) is a versatile machine learning algorithm used for classification and regression. It operates on the idea that similar data points are likely to have similar outputs. In KNN, the output is determined by the labels of the ‘k’ nearest data points. The most common method to calculate the distance between data points is the Euclidean distance."
      ],
      "metadata": {
        "id": "Dzqg4WGb6lbU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The choice of ‘k’ is important as a smaller ‘k’ makes the model sensitive to noise, while a larger ‘k’ makes it computationally expensive. Sometimes, the neighbors are weighted according to their distance, giving closer neighbors more influence. For a given data point to be classified or predicted, the distance to every other training data point is computed. The ‘k’ smallest distances and the corresponding data points are identified\n"
      ],
      "metadata": {
        "id": "30yUdZzq6qYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eucledian Distance\n",
        "$$d(P, Q) = \\sqrt{\\sum_{i=1}^{n} (q_i - p_i)^2}$$\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WbNo6Ez-6w6u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Z_1_GMKkidJ",
        "outputId": "b12d316d-591c-44fe-d20e-41e900299c1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy:77.5%\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "#This encoding function  checks the columns data values in the dataset; if they are strings then it converts int unique numerical values for the corresponding alphanumeric values.\n",
        "def encoding(df1):\n",
        "  for col in df1.columns:\n",
        "    if df1[col].dtype=='object':\n",
        "      convert={}# This is the dictionary I have used to check the unique alphanumeric values in a particular column in the database\n",
        "      flag=1\n",
        "      for item in df1[col]:\n",
        "        if item not in convert:\n",
        "          convert[item]=flag\n",
        "          flag+=1\n",
        "      df1[col]=df1[col].map(convert)\n",
        "      #Finally in this step we replace the entire column of alphanumeric values with integer values.\n",
        "  return df1\n",
        "\n",
        "#This common functions helps us to find the most common class of the k nearest neighbours of our testing data point.\n",
        "def common(labels):\n",
        "    lc={} #Here label is a dictionary that stores the key value pair of the two classes and their frequency in the k nearest neighbours.\n",
        "    for label in labels:\n",
        "        if label in lc:\n",
        "          lc[label]+=1\n",
        "        else:\n",
        "          lc[label]=1\n",
        "    #Here we finally calculate the number of times the class 1 and class 2 occurs in the knn and assign its value to the mcom variable and return it.\n",
        "    mcom=None\n",
        "    max=0\n",
        "    for label,count in lc.items():\n",
        "        if count>max:\n",
        "          max=count\n",
        "          mcom=label\n",
        "    return mcom\n",
        "\n",
        "#This predict function classifies the test point to get a predicted label with the help of helper function _predict\n",
        "def predict(X_train,y_train,X_test,k):\n",
        "    y_pred=[_predict(X_train,y_train,x,k) for x in X_test]\n",
        "    return np.array(y_pred) #Here we return an array of predicted labels for the test data point.\n",
        "\n",
        "#This is the helper function to the predict function here we actually calculate the Euclidean distance of the each test data point with the training data point.\n",
        "def _predict(X_train,y_train,x,k):\n",
        "    distances=[np.sqrt(np.sum((x_train-x)**2)) for x_train in X_train]#Calculating Euclideaen distance\n",
        "    k1=np.argsort(distances)[:k]#Here we find the indices of the k nearest neighbours\n",
        "    klabels=[y_train[i] for i in k1]#Here we get the corresponding class labels to the k nearest points to our testing data point.\n",
        "    mcom=common(klabels)\n",
        "    return mcom\n",
        "    #mcom is a variable that returns the most common class label occuring among the k values\n",
        "\n",
        "#We use the scaling function so that all the values in the different columns are normalized with respect to one another.\n",
        "#KNN model works by finding the Euclidean distance of the testing point with the other training points, and wrong scaling can affect the final decision to which class the point belongs to.\n",
        "def scaling(df1):\n",
        "    for column in df1.columns:\n",
        "        df1[column]=(df1[column]-df1[column].min())/(df1[column].max()-df1[column].min())\n",
        "    return df1\n",
        "df1 = encoding(df1)\n",
        "X = df1.drop('Risk', axis=1)\n",
        "X = scaling(X)\n",
        "y = df1['Risk']\n",
        "X_train,X_test,y_train,y_test=train_test_split(X.values,y.values,test_size=0.2,random_state=0)\n",
        "#we test for the value of k = 20 in th KNN Model. This means the closest 20 neighbours to our testing points will be considered to classify the testing points to the class.\n",
        "predictions=predict(X_train,y_train,X_test,k=15)\n",
        "\n",
        "print(f\"Model Accuracy:{accuracy_score(y_test,predictions)*100}%\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}